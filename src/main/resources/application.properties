spring.application.name=openai-demo

# Server configuration
server.port=8080
# Logging configuration
logging.level.root=INFO

# Ollama configuration
# Ollama API base URL and model         
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.model=llama3.2
spring.ai.ollama.embedding.model=llama3.2
spring.ai.ollama.chat.options.max-tokens=20
spring.ai.ollama.chat.options.temperature=0.7


